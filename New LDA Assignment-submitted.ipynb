{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3e167662",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "You have been provided with a multi dimensional data that contains information on certain\n",
    "images. Using machine learning, you should be able to predict the images on the new set of\n",
    "data using the model that you have trained on the existing data.\n",
    "Dataset Information:\n",
    "Each point in the data is an 8x8 image.\n",
    "Classes 10\n",
    "Samples per class ~180\n",
    "Samples total 1797\n",
    "Dimensionality 64\n",
    "Features integers 0-16\n",
    "Note: Load the dataset from sklearn.datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc47423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73101dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits=load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e198d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24bbf17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb936b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51b2cdf0",
   "metadata": {},
   "source": [
    "Q1. What will be the output of the following code?\n",
    "from sklearn import dataset\n",
    "digits = datasets.load_digits()\n",
    "1. Digits data from the sklearn module\n",
    "2. Import error\n",
    "3. Value error\n",
    "4. Digits data in a pandas dataframe\n",
    "\n",
    "Ans: 2. Import error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9dc9f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'dataset' from 'sklearn' (C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset\n\u001b[0;32m      2\u001b[0m digits \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mload_digits()\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'dataset' from 'sklearn' (C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn import dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "616f72b5",
   "metadata": {},
   "source": [
    "Q2. If we split the data in a ratio of 80% training and 20% testing data, what will be the correct\n",
    "code for the same?\n",
    "1. X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20, random_state=42)\n",
    "2. X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=80, random_state=42)\n",
    "3. X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "4. X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=80:20, random_state=42)\n",
    "\n",
    "Ans: 3. X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3708fe73",
   "metadata": {},
   "source": [
    "Q3. In the train_test_split, if we keep the random_state = 1, what does it mean for our training\n",
    "and testing data?\n",
    "1. Everytime the new random values are generated in the test and train sets\n",
    "2. The values will be the same every time the code is executed in the testing and training\n",
    "sets.\n",
    "3. None of the Above\n",
    "4. Both 1 and 2.\n",
    "\n",
    "Ans: 2. The values will be the same every time the code is executed in the testing and training sets."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b17d059e",
   "metadata": {},
   "source": [
    "Q4. In the code below, where we standardize the data, we have used the fit_transform() for the\n",
    "training sample, and transform() for the testing sample, why?\n",
    "1. We use the same mean and variance calculated on the training data to fit the test data\n",
    "2. The methods distinguish between the variance of each class\n",
    "3. The methods distinguish between mean and standard deviation of each class.\n",
    "4. None of the above\n",
    "\n",
    "Ans: 1. We use the same mean and variance calculated on the training data to fit the test data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6de84a45",
   "metadata": {},
   "source": [
    "Q5. Find the mistake in the code below?\n",
    "lda = LinearDiscriminantAnalysis(n_components=9)\n",
    "X_train = lda.fit_transform(X_train)\n",
    "X_test = lda.transform(X_test)\n",
    "1. Fit_transform() must include the y_train.\n",
    "2. transform() must include the y_train.\n",
    "3. None of the above\n",
    "4. Both 1 and 2\n",
    "\n",
    "Ans: 1. Fit_transform() must include the y_train."
   ]
  },
  {
   "cell_type": "raw",
   "id": "76e83478",
   "metadata": {},
   "source": [
    "Q6. What is the shape of the data after standardizing the training and testing data?\n",
    "1. (1437,64)\n",
    "2. (1797,64)\n",
    "3. (1437,9)\n",
    "4. (1437,)\n",
    "\n",
    "Ans: 1. (1437,64)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4ed98e0",
   "metadata": {},
   "source": [
    "Q7. What is the mistake in the code below?\n",
    "lda = LinearDiscriminantAnalysis(n_components=9)\n",
    "X_train = lda.fit_transform(X_train, X_test)\n",
    "X_test = lda.transform(X_test)\n",
    "1. X_test instead of y_train in fit_transform()\n",
    "2. X_test instead of y_train in transform()\n",
    "3. n_components = 9 is incorrect\n",
    "4. X_test instead of y_test in transform()\n",
    "\n",
    "Ans: 1. X_test instead of y_train in fit_transform()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee6bd450",
   "metadata": {},
   "source": [
    "Q8. How do you decide the n_components in the LinearDiscriminantAnalaysis()?\n",
    "1. Correlation coefficient\n",
    "2. variation inflation factor\n",
    "3. explained_variance_ratio\n",
    "4. None of the above\n",
    "\n",
    "Ans: 3. explained_variance_ratio"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6070e2a",
   "metadata": {},
   "source": [
    "Q9. If we keep the n_components as 15 in the LDA, what will be the shape of the data?\n",
    "1. (1797,15)\n",
    "2. (15,15)\n",
    "3. (15,)\n",
    "4. (1437, 15)\n",
    "\n",
    "Ans: 4. (1437, 15)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf5ddc61",
   "metadata": {},
   "source": [
    "Q10. After performing LDA on the standardized data, with n_components= 9, Create a random\n",
    "forest classifier to fit the new data with n_estimators= 100, and random_state same as used in\n",
    "train_test_split. After the above operation, what will be the accuracy score of the model?\n",
    "1. 0.75\n",
    "2. 0.85\n",
    "3. 0.95\n",
    "4. 0.98\n",
    "\n",
    "Ans: 3. 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c64bc1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35f1ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45608893",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49e20856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64)\n",
      "(360, 64)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_std.shape)\n",
    "print(X_test_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b6d4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e147d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 9)\n",
      "(360, 9)\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(n_components=9)\n",
    "X_train_lda = lda.fit_transform(X_train_std,y_train)\n",
    "X_test_lda=lda.transform(X_test_std)\n",
    "print(X_train_lda.shape)\n",
    "print(X_test_lda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7fb0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0657b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0155535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_lda,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6481f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_pred=rf.predict(X_test_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52e0815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 8, 8, 7, 3, 6, 2, 6, 5, 0, 5, 9, 3, 4, 4, 2, 4, 9, 9, 6, 3,\n",
       "       8, 1, 2, 5, 6, 0, 3, 4, 6, 7, 2, 6, 6, 6, 6, 5, 0, 9, 1, 7, 9, 6,\n",
       "       5, 7, 5, 2, 7, 5, 0, 8, 5, 5, 3, 2, 4, 0, 0, 2, 7, 5, 6, 1, 3, 7,\n",
       "       6, 5, 7, 0, 9, 0, 3, 8, 2, 5, 8, 2, 3, 5, 9, 3, 2, 7, 9, 6, 1, 1,\n",
       "       0, 6, 2, 9, 4, 4, 1, 2, 7, 8, 4, 2, 6, 9, 3, 7, 3, 9, 6, 9, 1, 0,\n",
       "       9, 2, 1, 6, 3, 4, 8, 7, 1, 0, 0, 4, 6, 5, 8, 2, 8, 1, 3, 0, 0, 8,\n",
       "       6, 4, 3, 9, 3, 3, 3, 3, 6, 7, 0, 0, 1, 9, 5, 8, 1, 5, 0, 6, 6, 6,\n",
       "       6, 1, 7, 7, 6, 7, 7, 8, 7, 3, 6, 5, 9, 0, 3, 8, 0, 9, 8, 1, 9, 5,\n",
       "       9, 5, 8, 9, 9, 7, 9, 1, 9, 5, 4, 7, 3, 0, 4, 9, 7, 7, 5, 6, 5, 8,\n",
       "       3, 4, 5, 4, 9, 2, 5, 5, 2, 1, 3, 8, 8, 9, 3, 6, 1, 0, 1, 4, 0, 5,\n",
       "       5, 6, 6, 7, 4, 3, 8, 4, 4, 0, 7, 9, 2, 8, 4, 9, 4, 2, 4, 0, 0, 0,\n",
       "       2, 6, 7, 0, 4, 5, 2, 2, 9, 0, 4, 6, 6, 2, 3, 9, 2, 3, 0, 6, 8, 7,\n",
       "       1, 4, 4, 1, 1, 6, 3, 8, 1, 2, 5, 7, 8, 3, 2, 0, 3, 4, 1, 9, 9, 9,\n",
       "       6, 3, 7, 1, 6, 9, 4, 7, 1, 8, 1, 3, 0, 5, 3, 4, 1, 9, 3, 5, 4, 7,\n",
       "       4, 1, 5, 1, 5, 0, 8, 8, 4, 2, 3, 8, 4, 1, 2, 0, 1, 1, 4, 4, 5, 7,\n",
       "       5, 0, 3, 2, 2, 4, 2, 7, 7, 8, 7, 6, 3, 1, 1, 5, 8, 8, 8, 6, 7, 2,\n",
       "       7, 8, 9, 4, 2, 0, 3, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7748fcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 8, 1, 7, 2, 6, 2, 6, 5, 0, 5, 9, 3, 4, 4, 2, 4, 9, 9, 6, 3,\n",
       "       8, 1, 2, 5, 6, 0, 3, 4, 6, 7, 2, 6, 6, 6, 6, 5, 0, 9, 1, 7, 9, 6,\n",
       "       5, 7, 5, 2, 7, 5, 0, 8, 5, 5, 3, 2, 4, 0, 0, 2, 7, 5, 6, 1, 3, 7,\n",
       "       6, 5, 7, 0, 9, 0, 3, 8, 2, 5, 8, 2, 3, 5, 9, 3, 2, 7, 9, 6, 8, 1,\n",
       "       0, 1, 2, 9, 4, 9, 1, 2, 7, 8, 4, 2, 6, 9, 3, 7, 3, 9, 6, 1, 1, 0,\n",
       "       9, 2, 1, 6, 3, 4, 8, 7, 1, 0, 0, 4, 6, 5, 8, 2, 8, 8, 3, 0, 0, 8,\n",
       "       6, 4, 3, 9, 3, 3, 3, 3, 0, 7, 0, 0, 1, 9, 5, 8, 1, 5, 0, 6, 6, 6,\n",
       "       6, 1, 7, 7, 6, 7, 7, 8, 7, 3, 6, 5, 9, 0, 3, 8, 0, 9, 8, 1, 9, 5,\n",
       "       9, 5, 8, 9, 9, 7, 9, 1, 9, 5, 4, 7, 3, 0, 4, 9, 7, 7, 5, 6, 5, 8,\n",
       "       3, 4, 5, 4, 9, 2, 5, 5, 2, 1, 3, 8, 8, 9, 3, 6, 1, 0, 1, 4, 0, 5,\n",
       "       5, 6, 6, 7, 4, 3, 8, 4, 1, 0, 7, 9, 2, 8, 4, 8, 4, 2, 4, 0, 0, 0,\n",
       "       2, 6, 7, 0, 4, 5, 2, 2, 9, 0, 4, 6, 8, 2, 3, 9, 2, 3, 0, 6, 8, 7,\n",
       "       1, 4, 4, 1, 1, 6, 3, 8, 1, 2, 5, 7, 8, 3, 2, 0, 3, 4, 1, 9, 9, 9,\n",
       "       6, 3, 7, 1, 6, 9, 4, 7, 1, 8, 1, 3, 0, 5, 3, 4, 1, 9, 3, 5, 4, 7,\n",
       "       4, 1, 5, 1, 5, 0, 9, 8, 4, 2, 3, 8, 4, 1, 2, 0, 1, 1, 4, 4, 5, 7,\n",
       "       5, 0, 3, 2, 2, 4, 2, 7, 7, 8, 7, 6, 3, 1, 1, 5, 8, 8, 8, 6, 7, 2,\n",
       "       7, 8, 9, 4, 2, 0, 3, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edabeb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9b71d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(y_test,y_pred)\n",
    "cf=confusion_matrix(y_test,y_pred)\n",
    "clrep=classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd4bcb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "[[35  0  0  0  0  0  1  0  0  0]\n",
      " [ 0 32  0  0  1  0  1  0  1  1]\n",
      " [ 0  0 34  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 37  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 36  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 37  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 36  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 36  0  0]\n",
      " [ 0  2  0  0  0  0  1  0 31  1]\n",
      " [ 0  0  0  0  1  0  0  0  1 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        36\n",
      "           1       0.94      0.89      0.91        36\n",
      "           2       1.00      0.97      0.99        35\n",
      "           3       0.97      1.00      0.99        37\n",
      "           4       0.95      1.00      0.97        36\n",
      "           5       1.00      1.00      1.00        37\n",
      "           6       0.92      1.00      0.96        36\n",
      "           7       1.00      1.00      1.00        36\n",
      "           8       0.94      0.89      0.91        35\n",
      "           9       0.94      0.94      0.94        36\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(cf)\n",
    "print(clrep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a868b3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35,  0,  0,  0,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0, 32,  0,  0,  1,  0,  1,  0,  1,  1],\n",
       "       [ 0,  0, 34,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 37,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 36,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 37,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 36,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 36,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  0,  1,  0, 31,  1],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  0,  1, 34]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26d0bc6b",
   "metadata": {},
   "source": [
    "Q11. Identify the mistake in the code below.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, X_test)\n",
    "1. X_test instead of y_test\n",
    "2. X_test instead of y_train\n",
    "3. X_test instead of n_components = 9\n",
    "4. Missing parameter - random_state=42\n",
    "\n",
    "Ans: 2. X_test instead of y_train"
   ]
  },
  {
   "cell_type": "raw",
   "id": "726a01e7",
   "metadata": {},
   "source": [
    "Q12. What percentage of positive cases was the model able to catch for class 6?\n",
    "1. 100\n",
    "2. 97\n",
    "3. 35\n",
    "4. 99\n",
    "\n",
    "Ans:2. 97"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0de3be27",
   "metadata": {},
   "source": [
    "Q13. What percentage of the predictions were true for class 5?\n",
    "1. 96\n",
    "2. 47\n",
    "3. 98\n",
    "4. 0.98\n",
    "\n",
    "Ans: 3. 98"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6061959b",
   "metadata": {},
   "source": [
    "14. What percentage of positive predictions were correct for class 3?\n",
    "1. 34\n",
    "2. 92\n",
    "3. 97\n",
    "4. 94\n",
    "\n",
    "Ans: 4. 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7227a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
